<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Zinan Chi</title>
    <link id="favicon" rel="icon" type="image/png" href="img/zc_logo4.png" />
    <link rel="stylesheet" href="css/s_general.css" tyle="text/css" />
    <link rel="stylesheet" href="css/s_projects.css" tyle="text/css" />

    <link
      href="https://fonts.googleapis.com/css?family=Arimo:400,500,600,700"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Lato:300,400,500,600,700"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Libre Bodoni"
      rel="stylesheet"
    />
    <link
      href="https://fonts.googleapis.com/css?family=Roboto Slab"
      rel="stylesheet"
    />
  </head>
  <body>
    <div id="splash">
      <img id="splash-image" src="img/splash_screen_2.png" alt="" />
    </div>

    <nav class="Menu" id="Menu-home" style="display: none">
      <div class="Container-Menu">
        <div class="Container-flex">
          <div class="Menu-title Menu-item">
            <a href="index.html">ZN </a>
          </div>
          <div class>
            <div class="Menu-item">
              <a id="Menu-work" href="work.html">Work</a>
            </div>
            <div class="Menu-item">
              <a id="Menu-about" href="zc.html">About</a>
            </div>
            <div class="Menu-item">
              <a id="Menu-contact" >Contact</a>
            </div>
          </div>
        </div>
      </div>
    </nav>

    <main>
      <div id="main-content" style="display: none">
        <div
          id="section-cover"
          class="background-image-wrap project-cover"
          style="background-image: url('img/hls_01_4.png')"
        >
          <div class="Container-project-title">
            <div>
              <h2>Harvard Library</h2>
              <h3>
                <b>AI Cataloger</b>
              </h3>
              <p>
                Build an GEN-AI powered workflow to generate book subject
                headings for library catalogers using LLM and Retrieval
                Augmented Generation, result in a 2.62% time consumption.
              </p>
            </div>
          </div>
        </div>
        <div class="Container-cluster">
          <div class="info Container-3">
            <div>
              <p class="content-text" style="font-weight: 900">Role</p>
              <p class="content-text">
                AI Engineer<br />
                Product Lead
              </p>
            </div>
            <div>
              <p class="content-text" style="font-weight: 900">Tools</p>
              <p class="content-text">
                LLM<br />
                RAG (Langchain)<br />
                React<br />
              </p>
            </div>
            <div>
              <p class="content-text" style="font-weight: 900">Timeline</p>
              <p class="content-text">Apr 2023 - Present</p>
            </div>
          </div>
        </div>

        <div id="side-nav">
          <div class="dot" hidden></div>
          <div class="dot" hidden></div>
          <div class="dot" hidden></div>
          <div class="dot" hidden></div>
          <div class="dot" hidden></div>
          <div class="dot" hidden></div>
        </div>

        <div id="side-nav-content">
          <div class="Container-cluster">
            <h3 class="content-title">Library & Data & AI</h3>
            <p class="content-text">
              The task of a cataloger heavily relies on knowledge and
              experience, which are strengths of current LLMs. Cataloging is
              also an iterative process that doesn’t aim for high accuracy on
              the first try. These features make it intuitive to involve more
              AI-related investigations in the current library system. It’s
              about data. It’s about text. LLMs are efficient, multilingual, and
              scalable. How can Generative-AI technology help streamline library
              work?
            </p>
            <div class="Container-2-left" style="margin: auto">
              <div class="Container-image">
                <img src="img/hls_06_1.png" alt />
              </div>
              <div>
                <p class="content-annotation">
                  <b>Title & Summary</b><br />
                  Book titles and summary cover the gist of the content. Library
                  Catalogers assign subject headings by reading those two
                  fields.
                </p>
                <p class="content-annotation">
                  <b>Subject Headings</b><br />
                  Subject headings are the handles linking a book and the
                  knowledge network. Accurate subject headings ensure readers
                  can easily access the information they seek and connect
                  related content. When books are acquired by Harvard Library,
                  catalogers assign headings based on the book's title and
                  summary.
                </p>
                <p class="content-annotation">
                  <b>ISBN</b><br />
                  ISBN is book's unique identifier.
                </p>
              </div>
            </div>
          </div>

          <section>
            <div class="box-right" style="background: #f3f3f3"></div>
            <div
              class="Container-full"
              style="
                background: #f3f3f3;
                padding-top: 0 !important;
                padding-bottom: 0px;
              "
            >
              <div class="Container-cluster" style="padding-bottom: 0px">
                <h5 class="section" style="border-left: 1.4rem solid #9c5856">
                  GEN-AI
                </h5>
                <h3 class="content-title">
                  Use LLM to Generate Subject Headings with book titile and
                  summary
                </h3>
                <p class="content-text">
                  LLM for book cataloging utilizes advanced
                  <b> natural language processing</b> capabilities to understand
                  and extract relevant concepts from provided texts. By
                  analyzing the title and summary, the LLM can identify key
                  themes and topics, assigning appropriate subject headings and
                  positioning them among the right neighbors in knowledge
                  networks. <br /><br />This approach not only automates the
                  cataloging process, but also reduces the need for specialized
                  expertise in subject classification. Additionally, using an
                  LLM helps to standardize the classification process,
                  potentially minimizing human error and bias in the assignment
                  of subject terms.
                </p>
                <video autoplay loop muted width="100%">
                  <source type="video/mp4" src="img/hls_28.mp4" />
                </video>
              </div>
            </div>
            <div class="box-left" style="background: #f3f3f3"></div>
          </section>

          <section class="Container-cluster" style="padding-top: 0px">
            <h5 class="section" style="border-left: 1.4rem solid #9c5856">
              Proof of Concept
            </h5>
            <h3 class="content-title">Learn the Limitation of Vanilla LLMs</h3>
            <p class="content-subtitle">Early Experiment</p>
            <p class="content-text">
              The initial version using ChatGPT (GPT-3.5) appears promising.
              After evaluating <b>400 items</b>, it achieved
              <b>70% accuracy</b> and required <b>half time</b> as an
              experienced cataloger for assigning subject headings. It also
              eliminates the need for high domain knowledge and lowers the
              professional bar for the task. <br /><br />
              However, while library catalogers recognize the potential of LLMs,
              they are still far from being directly integrated into the current
              workflow. Early experiments highlighted <b>challenges</b> with the
              vanilla version, prompting us to investigate multiple solutions to
              improve accuracy and <b>enhance Human-AI interaction</b>.
            </p>
            <div class="Container-full Container-image">
              <img src="img/hls_07_1.png" alt />
            </div>

            <p class="content-subtitle">
              Challenges of GenAI for Book Cataloging
            </p>
            <div>
              <p class="content-text">
                <b>1. Lack of Stability and Hallucinations</b>
              </p>
              <p class="content-annotation">
                The generated subject headings can vary between different runs
                with a 70% similarities between each runs. This randomness
                undermines the reliability needed for consistent cataloging
                practices. Meanwhile, LLMs can sometimes generate incorrect or
                overconfident information, often referred to as
                "hallucinations."
              </p>
            </div>

            <div>
              <p class="content-text">
                <b>2. Difficulty Distinguishing Types of Subject Headings</b>
              </p>
              <p class="content-annotation">
                Subject headings have different authorities, like Library of
                Congress Subject Headings (LCSH) and Faceted Application of
                Subject Terminology (FAST), etc. With LLM trained on both data,
                it often misuse lcsh subject heading in its response.
              </p>
            </div>
            <div>
              <p class="content-text">
                <b>3. Human-AI Interaction</b>
              </p>
              <p class="content-annotation">
                The LLM response is barebone. It requires librarians' effort to
                find book titile adn summaries online, and post-proceed the AI
                response to accurate and right-format responses. To better
                facilitate the workflow, we want the application to perfom
                closer to an agent and take over the end-to-end task with human
                interaction and intervention.
              </p>
            </div>
          </section>

          <section
            id="section2"
            class="Container-full background-image-wrap"
            style="
              background-image: url('img/hls_19.png');
              width: 90%;
              margin: 0px auto;
              padding-bottom: 0px;
            "
          ></section>

          <div class="Container-cluster" style="padding-top: 0px">
            <h5 class="section" style="border-left: 1.4rem solid #9c5856">
              Experiments
            </h5>
            <h3 class="content-title">Overlaps among Multiple LLM Responses</h3>

            <div class="Container-2">
              <div>
                <p class="content-text">
                  <b>Challenge</b>
                </p>
                <p class="content-text">
                  <b>1. Lack of Stability and Hallucinations</b>
                </p>
                <p class="content-annotation">
                  The generated subject headings can vary between different runs
                  with a 70% similarities between each runs. This randomness
                  undermines the reliability needed for consistent cataloging
                  practices. Meanwhile, LLMs can sometimes generate incorrect or
                  overconfident information, often referred to as
                  "hallucinations."
                </p>
              </div>
              <div>
                <p class="content-text">
                  <b>Solution</b>
                </p>
                <p class="content-text">
                  <b
                    >1. Overlaps among Multiple LLM Responses and
                    Cross-reference with FAST API
                  </b>
                </p>
                <p class="content-annotation">
                  We propose running the title through three different
                  foundation models and assigning higher weights to the
                  overlapping headings to counterbalance the randomness. By
                  cross-referencing with the FAST API, we filter out options
                  that lack accurate related FAST headings.
                </p>
              </div>
            </div>
            <p class="content-text">
              To address the inherent instability and occasional inaccuracies in
              LLM-generated subject headings, a more robust approach is
              necessary. This involves leveraging
              <b>multiple Foundation Models</b> to generate subject headings and
              then <b>cross-referencing</b> these outputs with established
              databases to filter out errors. The following experiment and its
              analysis delve into the effectiveness of this approach, presenting
              an <b>21.4% accuracy improvement </b>compared to a single
              response.
            </p>
            <div class="Container-4" style="margin: 0px">
              <div>
                <p class="content-text">
                  <b class="content-title"> 214 </b> Book Items<br />
                  <b class="content-title"> 3 </b> AI bots <br />
                  <b class="content-title"> 642 </b> Queries
                </p>
              </div>
              <div>
                <p class="content-text">
                  <b class="content-title">98.6% </b> responses are valid
                  cross-referencing SearchFast API.
                </p>
              </div>
              <div></div>
              <div>
                <p class="content-text">
                  <b class="content-title"> 9 </b> mins cross-referencing
                  SearchFast API for 856 items.
                </p>
              </div>
              <div>
                <p class="content-text">
                  <b class="content-title"> 192</b>
                  out of 214 have overlapped options among 4 bots.
                </p>
              </div>
              <div>
                <p class="content-text">
                  <b class="content-title"> 89.7% </b> Overlap ratio for
                  multiple LLM resposne.<br />
                </p>
              </div>
              <div>
                <p class="content-text">
                  <b class="content-title"> 121.4% </b> accuracy compared to a
                  single AI bot response.
                </p>
              </div>
            </div>
            <div class="Container-image" style="padding-top: 40px">
              <img src="img/hls_21.png" />
            </div>
            <!-- <div class="Container-image">
              <img src="img/hls_15.png" class="" />
            </div> -->
          </div>

          <section class="Container-cluster">
            <h5 class="section" style="border-left: 1.4rem solid #9c5856">
              Experiments
            </h5>
            <h3 class="content-title">
              Retrieval Augumented Generation (RAG) with library data and Prompt
              Engineering
            </h3>

            <div class="Container-2">
              <div>
                <p class="content-text">
                  <b>Challenge</b>
                </p>
                <p class="content-text">
                  <b>2. Difficulty Distinguishing Types of Subject Headings</b>
                </p>
                <p class="content-annotation">
                  Subject headings have different authorities, like Library of
                  Congress Subject Headings (LCSH) and Faceted Application of
                  Subject Terminology (FAST), etc. With LLM trained on both
                  data, it often misuse lcsh subject heading in its response.
                </p>
              </div>
              <div>
                <p class="content-text">
                  <b>Solutions</b>
                </p>
                <p class="content-text">
                  <b>2.1 Prompt Engineering</b>
                </p>
                <p class="content-annotation">
                  To improve the subject headings, we engineer the prompt to
                  describe the difference of FAST headings in details to help
                  LLMs generate the correct content and ideal format.
                </p>
                <p class="content-text">
                  <b
                    >2.2 Retrieval Augumented Generation (RAG) with library
                    data</b
                  >
                </p>
                <p class="content-annotation">
                  Using the book items in the library database, we established
                  our dataset to retrieve relevant books as references for
                  generating subject headings for new books. The retrieved
                  relevant book is added as part of the prompt for LLMs to
                  reference.
                </p>
              </div>
            </div>
            <p class="content-subtitle">Prompt Engineering</p>
            <p class="content-text">
              With an LLM functioning as a blackbox from the user's perspective,
              the primary interface is the prompt. The prompt guides the model
              to retrieve and generate relevant content from its vast training
              data. Through trial and error, we learned the importance of
              providing detailed context and avoiding irrelevant or misleading
              keywords like "LCSH." Another approach involved asking the LLM to
              provide related book information and refer to their subject
              headings, but this resulted in worse performance. The model often
              responded with "Sorry," increasing the chance of failure.
            </p>
            <p class="content-subtitle">
              Retrieval Augumented Generation (RAG)
            </p>
            <p class="content-text">
              We used Langchain to implement the RAG model. Using Harvard
              LibraryCloud API, we gathered 10k books with summaries. 4,000
              items have subject headings in FAST classification type. Using
              those 4,000 books as inital dataset, we append the RAG model
              before the LLM, prompting to retreive the closest book with the
              new book. We input the new book query and the context as the
              related book inforamtion to the LLM. The result is significantly
              improved. Here are some examples. <br />
            </p>
            <div class="Container-image" style="padding-top: 40px">
              <img src="img/hls_20.png" />
            </div>
            <!-- <div class="Container-2 Container-full">
              <div class="Container-image">
                <img src="img/hls_17.png" class="" />
                <p class="content-text">
                  <b>Prompt Engineering </b> &mdash; The trial and test prompt
                  has three major progression -- the more context it contains,
                  the more text it gain.
                </p>
              </div>
              <div class="Container-image">
                <img src="img/hls_18.png" class="" />
              </div>
            </div> -->
          </section>

          <section class="Container-cluster">
            <h5 class="section" style="border-left: 1.4rem solid #9c5856">
              Human-AI Interaction
            </h5>
            <h3 class="content-title">
              AI Agent - Reveal Steps and Allow User Interaction
            </h3>

            <div class="Container-2">
              <div>
                <p class="content-text">
                  <b>Challenge</b>
                </p>
                <p class="content-text">
                  <b>3. Human-AI Interaction</b>
                </p>
                <p class="content-annotation">
                  The LLM response is basic and requires significant effort from
                  librarians to find book titles and summaries online and
                  post-process the AI response for accuracy and proper
                  formatting. To enhance the workflow, we aim for the
                  application to function more like an agent, handling the
                  entire task with opportunities for human interaction and
                  intervention.
                </p>
              </div>
              <div>
                <p class="content-text">
                  <b>Solution</b>
                </p>
                <p class="content-text">
                  <b>3. AI Agent - Reveal Steps and Allow User Interaction</b>
                </p>
                <p class="content-annotation">
                  The AI cataloger is designed as an end-to-end product that
                  reveals results at each step, permits manual modifications,
                  and facilitates better human-AI interaction through its
                  design. By creating a transparent workflow, we can also
                  evaluate performance by isolating the results at each step.
                </p>
              </div>
            </div>
            <p class="content-text">
              Given the limitations of the vanilla LLM query, we have developed
              an end-to-end workflow extending beyond a simple AI bot query. Our
              previous experiments and tests showed that each step doesn't
              ensure a 100% success rate. To improve this, we've made the
              process more transparent to facilitate better debugging, user
              engagement, and workflow analysis. Users can input book
              information, modify query details, review the AI responses and
              FAST API results, and make adjustments based on their expertise.
              This comprehensive approach ultimately produces the subject
              headings for the book item.
            </p>
            <video autoplay loop muted width="100%">
              <source type="video/mp4" src="img/hls_13.mp4" />
            </video>
            <div class="Container-full" style="padding-bottom: 0px !important">
              <div
                class="Container-galleries"
                style="margin-bottom: 60px !important"
              >
                <div
                  class="gallery-image  gallery-display"
                  style="background-image: url('img/hls_23.png')"
                ></div>
                <div
                  class="gallery-image"
                  style="background-image: url('img/hls_24.png')"
                ></div>
                <div
                  class="gallery-image"
                  style="background-image: url('img/hls_26.png')"
                ></div>
                <div
                  class="gallery-image"
                  style="background-image: url('img/hls_27.png')"
                ></div>
                <div
                  class="gallery-image"
                  style="background-image: url('img/hls_25.png')"
                ></div>
                <div
                  class="gallery-image"
                  style="background-image: url('img/hls_22.png')"
                ></div>
              </div>
              <div class="Container-galleries-text">
                <p class="content-text">
                  <b>Title Input</b> &mdash; Customizable title input, which can
                  be found on vendor websites or within the Alma library data
                  system.
                </p>
                <p class="content-text" hidden>
                  <b>Summary Input</b> &mdash; Customizable summary input, which
                  can be filled in with the book blurb from vendor websites.
                </p>
                <p class="content-text" hidden>
                  <b>Prompt Input</b> &mdash; Users can adjust the prompt as
                  they test. However, we suggest sticking with a prompt and
                  collecting results to analyze its performance. Once an ideal
                  prompt is identified, it should be consistently used.
                </p>
                <p class="content-text" hidden>
                  <b>Response and FAST API Cross-Referencing</b> &mdash; In each
                  AI bot panel, users can expand to see the original response
                  and the result after cross-referencing with the FAST API.
                </p>
                <p class="content-text" hidden>
                  <b>FAST API Interface</b> &mdash; When users identify a
                  potentially better FAST Heading related to an AI response,
                  they can manually search using a panel. Instead of displaying
                  only the top matching FAST Heading, we show the top three
                  matches for users to choose from.
                </p>
                <p class="content-text" hidden>
                  <b>FAST Heading Final Adjustment and Export</b> &mdash; Once a
                  better heading is identified, it can be added to the next
                  panel. Overlapping headings are displayed at the top,
                  indicating a higher likelihood of accuracy. Single-occurrence
                  headings are shown in a lower section. Users can customize the
                  sequence and adjust the selections as needed.
                </p>
              </div>
            </div>
          </section>

          <div class="box-right" style="background: #f3f3f3"></div>
          <div
            class="Container-full Container-image"
            style="background: #f3f3f3"
          >
            <div style="width: 80%; margin: 60px auto">
              <video
                autoplay
                loop
                muted
                width="100%"
                style="margin-right: auto"
              >
                <source
                  type="video/mp4"
                  src="img/hls_08.mp4"
                  preload="auto"
                  poster="img/mw_031.png"
                />
              </video>
            </div>
          </div>
          <div class="box-left" style="background: #f3f3f3"></div>

          <section class="Container-cluster">
            <div>
              <h5 class="section" style="border-left: 1.4rem solid #9c5856">
                Thoughts
              </h5>

              <h3 class="content-title">GEN-AI to Application</h3>
              <p class="content-subtitle">
                Synthesize Information and Define Scope
              </p>
              <p class="content-text">
                With the release of ChatGPT, AI is expanding into professions
                beyond what we previously imagined. The integration of Gen-AI
                into library cataloging holds transformative potential for the
                industry. Developing an LLM for this purpose involves an
                iterative process, with book cataloger from different library
                editting, collaborating, and improving the headings continously.
                , leaving a relatively high error toleration for book
                classification. Compared to library cataloger using their
                knowledge and subjective assessment, the AI cataloger is more
                consistant in this manner and can sustain the process.
              </p>
              <p class="content-subtitle">AI bot to AI Agent</p>
              <p class="content-text">
                With the proof of concept of using Gen-AI to assist in subject
                heading generation, building it into an application is a
                significant leap forward. One challenge is designing the user
                experience: we aim to provide an automated system that still
                allows users to engage with the model and its details.
                <br /><br />The AI Cataloger assists in the initial stage of the
                task, reducing some of the manual, tedious parts. However,
                nuances and details are hard to capture. I initiated some
                observations with experienced library catalogers to improve the
                algorithm, such as separating the algorthm processing topic and
                geographical FAST headings. In the short run, we still need
                professionals to help fine-tune the system.
              </p>
            </div>
          </section>
        </div>

        <div class="Container-cluster Container-2">
          <a id="prev" class="nav-bottom" href="porsche.html">
            <img class="image-80" src="img/06.jpg" />
            <div class="section">PREV</div>
            <div class="foot-text">porsche retail</div>
            <div class="tag-div content-annotation">
              <p>3D Experience</p>
              <p>Interior</p>
              <p>Brand</p>
            </div>
          </a>
          <a id="next" class="nav-bottom" href="morrow.html">
            <img class="image-80" src="img/mw_000.gif" />
            <div class="section">NEXT</div>
            <div class="foot-text">morrow</div>
            <div class="tag-div content-annotation">
              <p>PRD</p>
              <p>UI UX</p>
              <p>Interactive Prototype</p>
            </div>
          </a>
        </div>
      </div>
    </main>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
    <script src="js/f_sidebar.js" type="text/javascript"></script>
    <script src="js/f_phase.js" type="text/javascript"></script>
    <script src="js/f_splash.js" type="text/javascript"></script>
    <script src="js/f_gallery.js" type="text/javascript"></script>
    <script src="js/f_contact.js" defer type="text/javascript"></script>
    <script src="js/window.js" type="text/javascript"></script>

  </body>
</html>
